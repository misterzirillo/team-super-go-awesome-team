from ea import EA
from mlpnetwork import MLPNetwork
import numpy as np
import random

class GA(EA):
    
    def __init__(self, shape, mu):
        #super(shape, max)
        super().__init__(shape, mu)
        self.parents = []
        
    def check(self):
        print(self.shape, self.trueShape, len(self.pop[1]), self.pop[1][1:10])
        
    
    def train(self, x, y, maxGen):
        
        #mark the time step, or generation
        t = 0
        
        self.fitness={}
        self.fitnext={}

        #evaluate the fitness of the population
        #need to establish train_set, validation_set#######
        for i in range(len(self.pop)):
            self.fitness.update({i : self.evaluateFitness(self.pop[i], x, y)})
        
        #sort by fitness
        self.sortFit = sorted(self.fitness.items(), key=lambda x:x[1])
        
        #store current best individual
        best = max(self.fitness, key=(lambda key: self.fitness[key]))

        while(t <= maxGen):
            #create test_fold
            
            t = t +1
            self.selectFrom()
            offSpring = self.crossOver()
            newPop = self.mutate(offSpring)
            #print(offSpring)

            #add each child to population
            for i in range(len(newPop)):
                self.pop.append(newPop[i])
                        
            #new pop list
            self.sortPop = sorted(self.pop, key=lambda j:self.evaluateFitness(j, x, y))
            self.pop = self.sortPop[len(newPop):]
            
            #update
            for i in range(len(self.pop)):
                self.fitness.update({i : self.evaluateFitness(self.pop[i], x, y)})          
            
            #new sortFit list
            self.sortFit = sorted(self.fitness.items(), key=lambda x:x[1])
 
            
            #store current best individual
            best = self.pop[-1]
            
            print(self.sortFit[-1][1])
            
            if(t== maxGen):
                #return(best)
                break
          
    #evaluate the fitness of the population on some loss function
    def evaluateFitness(self, individual, x, y): 

        # maybe optimize this later with pre-created networks
        rehydrated = MLPNetwork(self.shape)
        rehydrated.weights = self.uncereal(individual)

        hypothesis = rehydrated.propagate(x)

        corrects = [hi.argmax() == yi.argmax() for hi, yi in zip(hypothesis, y)]

        return (np.sum(corrects) / len(y)) * 100
    
    #select the parents from the population
    #rank based
    #bugs, never picking the worst or best individual
    def selectFrom(self):
        super().selectFrom()
        self.parents = []
        n = len(self.pop)
        #expected number of offspring generated by the best individual
        lam1 = 1.99
        #expected number of offspring generated by the best individual
        lam2 = 2-lam1
   
        Pxi = []
        wheel = []

        #assign probability of selection
        #calculate cumulative fitness and make roulette wheel
        for i in range(len(self.pop)):
            #normalizer
            Pxi.append((lam2 + (i/(n-1)) * (lam1 - lam2)) / n)
            
            wheel.append((sum(Pxi), self.sortFit[i]))
        
        #generate two random numbers in the range of the wheel to find parents        
        num = random.uniform(0, sum(Pxi))
        i = 0
        while(True):
            if wheel[i][0] > num:
                self.parents.append(wheel[i][1])
                break
            else:
                i = i+1
        i=0
        num = random.uniform(0, sum(Pxi))
        while(True): 
            if wheel[i][0] > num:
                if(wheel[i][0]!=self.parents[0]):
                    self.parents.append(wheel[i][1])
                    return
                else:
                    num = np.random(0, sum(Pxi))
                    i=0
            else:
                i=i+1
        
    #generate offspring according to the crossover rate
    #global, uniform
    # should return a whole new copy of the population
    # example: self.pop = self.crossOver()
    def crossOver(self):
        super().crossOver()
        
        offspring=[]
        x1 = self.pop[self.parents[0][0]]
        #for each other parent, pair it with x1
        for i in range(1, len(self.parents)):
            offspring.extend(self.uniCross(x1, self.pop[self.parents[i][0]]))
        
        return(offspring)
        
    #given two parents, create two offspring using a binary mask
    def uniCross(self, x1, x2):
        spawn = []
        goodTwin = []
        evilTwin = []
        mask =[]
       #chromLength = len(self.pop[self.parents[0][0]])
        chromLength = len(x1)
        #x2 = self.pop[self.parents[1][0]]
        #print(x1[0:2])
        #print(x2[0:2])
        
        #build binary mask
        for i in range(chromLength):
            mask.append(random.randint(0, 1))
        #print(mask[0:2])
    
        #create first offspring
        for i in range(chromLength):
            if mask[i] == 1:
                goodTwin.append(x1[i])
            else:
                goodTwin.append(x2[i])
        spawn.append(goodTwin)
        #create second offspring     
        for i in range(chromLength):
            if mask[i] == 1:
                evilTwin.append(x2[i])
            else:
                evilTwin.append(x1[i])
        spawn.append(evilTwin)
        
        #print(spawn[0][0:2])
        return spawn
        

    #mutate the offspring according to the mutation rate
    # should return a whole new copy of the population
    # example: self.pop = self.mutate()

    def mutate(self, specimens):
        super().mutate()
        #probability of mutation on a feature
        Pm =.1
        check = []
        for i in range(len(specimens)):
            for j in range(len(specimens[i])):
                num = random.random()
                if(num < Pm):
                    specimens[i][j] = random.normalvariate(specimens[i][j], 1)
                    check.append(("yes", (i, j)))
                else:
                    check.append(("no", (i, j)))
            #print(check)
        return(specimens)
                    
    #find the slackers and replace them with new dudes
    def replace(self, newPop, fitNext):
        for i in range(len(newPop)-1):
            pass

        
        
        
        
        
        
        
        
        
                
            
    